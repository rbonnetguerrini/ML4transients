{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682e31b7",
   "metadata": {},
   "source": [
    "```sh\n",
    "python scripts/run_evaluation.py     \n",
    "    --config configs/evaluation_config.yaml     \n",
    "    --data-path /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm \n",
    "    --weights-path /sps/lsst/groups/transients/HSC/fouchez/raphael/training/simple_run     \n",
    "    --output-dir saved/test_eval     \n",
    "    --interpretability \n",
    "    --model-hash \"6d5bb4aa\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5906ef7a",
   "metadata": {},
   "source": [
    "# Model Evaluation Example Notebook\n",
    "\n",
    "This notebook demonstrates how to use the ML4transients evaluation framework to comprehensively evaluate trained models. It covers:\n",
    "\n",
    "1. **Basic Metrics Evaluation** - Computing standard classification metrics\n",
    "2. **Interactive Dashboards** - Creating Bokeh-based visualization dashboards  \n",
    "3. **Interpretability Analysis** - UMAP-based model interpretability with clustering\n",
    "4. **Comparative Analysis** - Comparing multiple models\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Trained model weights directory with `config.yaml` and `model_best.pth`\n",
    "- Dataset with cutouts and features\n",
    "- Optional: Existing inference results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d57792c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Add ML4transients to path\n",
    "sys.path.append('/sps/lsst/users/rbonnetguerrini/ML4transients/src')\n",
    "\n",
    "from ML4transients.data_access import DatasetLoader\n",
    "from ML4transients.evaluation.metrics import EvaluationMetrics\n",
    "from ML4transients.evaluation.visualizations import (\n",
    "    create_evaluation_dashboard, \n",
    "    create_interpretability_dashboard,\n",
    "    BokehEvaluationPlots,\n",
    "    UMAPVisualizer\n",
    ")\n",
    "from ML4transients.evaluation.interpretability import UMAPInterpreter\n",
    "from ML4transients.training.pytorch_dataset import PytorchDataset\n",
    "\n",
    "# Configure display settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a97c6",
   "metadata": {},
   "source": [
    "## 1. Configuration and Data Loading\n",
    "\n",
    "First, let's set up paths and load our dataset. Modify these paths according to your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2d072aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm\n",
      "Model weights: /sps/lsst/groups/transients/HSC/fouchez/raphael/training/simple_run\n",
      "Output directory: ../saved/test_eval/notebook\n"
     ]
    }
   ],
   "source": [
    "# Configuration - MODIFY THESE PATHS\n",
    "DATA_PATH = \"/sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm\"  # Path to directory containing cutouts/ and features/\n",
    "WEIGHTS_PATH = \"/sps/lsst/groups/transients/HSC/fouchez/raphael/training/simple_run\"  # Path to trained model directory\n",
    "OUTPUT_DIR = \"../saved/test_eval/notebook\"\n",
    "\n",
    "# Optional: Model hash for existing inference results\n",
    "MODEL_HASH = \"6d5bb4aa\"  \n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path(OUTPUT_DIR)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data path: {DATA_PATH}\")\n",
    "print(f\"Model weights: {WEIGHTS_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3134bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded inference registry from /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm/inference/inference_registry.json\n",
      "\n",
      "DatasetLoader(40 visits, 1 paths)\n",
      "  Cutouts: 57905 across 40 visits\n",
      "  Features: 57905 across 40 visits\n",
      "Available visits: [322, 346, 358, 1178, 1184, 1204, 1206, 1214, 1220, 1242]...\n",
      "\n",
      "Checking for existing inference results...\n",
      "Syncing inference registry for /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm...\n",
      "Saved inference registry to /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm/inference/inference_registry.json\n",
      "Registry sync complete: added 0, removed 0 entries\n",
      "Available inference files in /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm:\n",
      "  Visit 1214:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1214_inference_6d5bb4aa.h5\n",
      "  Visit 29336:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_29336_inference_6d5bb4aa.h5\n",
      "  Visit 22662:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_22662_inference_6d5bb4aa.h5\n",
      "  Visit 358:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_358_inference_6d5bb4aa.h5\n",
      "  Visit 17904:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17904_inference_6d5bb4aa.h5\n",
      "  Visit 23718:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_23718_inference_6d5bb4aa.h5\n",
      "  Visit 19696:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_19696_inference_6d5bb4aa.h5\n",
      "  Visit 17948:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17948_inference_6d5bb4aa.h5\n",
      "  Visit 1178:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1178_inference_6d5bb4aa.h5\n",
      "  Visit 11694:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11694_inference_6d5bb4aa.h5\n",
      "  Visit 11740:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11740_inference_6d5bb4aa.h5\n",
      "  Visit 11696:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11696_inference_6d5bb4aa.h5\n",
      "  Visit 1204:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1204_inference_6d5bb4aa.h5\n",
      "  Visit 1220:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1220_inference_6d5bb4aa.h5\n",
      "  Visit 17926:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17926_inference_6d5bb4aa.h5\n",
      "  Visit 30490:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_30490_inference_6d5bb4aa.h5\n",
      "  Visit 17950:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17950_inference_6d5bb4aa.h5\n",
      "  Visit 19684:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_19684_inference_6d5bb4aa.h5\n",
      "  Visit 17900:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17900_inference_6d5bb4aa.h5\n",
      "  Visit 19680:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_19680_inference_6d5bb4aa.h5\n",
      "  Visit 23706:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_23706_inference_6d5bb4aa.h5\n",
      "  Visit 17906:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17906_inference_6d5bb4aa.h5\n",
      "  Visit 23694:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_23694_inference_6d5bb4aa.h5\n",
      "  Visit 22632:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_22632_inference_6d5bb4aa.h5\n",
      "  Visit 30482:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_30482_inference_6d5bb4aa.h5\n",
      "  Visit 1206:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1206_inference_6d5bb4aa.h5\n",
      "  Visit 346:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_346_inference_6d5bb4aa.h5\n",
      "  Visit 11710:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11710_inference_6d5bb4aa.h5\n",
      "  Visit 11698:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11698_inference_6d5bb4aa.h5\n",
      "  Visit 23704:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_23704_inference_6d5bb4aa.h5\n",
      "  Visit 11738:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11738_inference_6d5bb4aa.h5\n",
      "  Visit 1184:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1184_inference_6d5bb4aa.h5\n",
      "  Visit 11704:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11704_inference_6d5bb4aa.h5\n",
      "  Visit 1242:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1242_inference_6d5bb4aa.h5\n",
      "  Visit 19694:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_19694_inference_6d5bb4aa.h5\n",
      "  Visit 322:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_322_inference_6d5bb4aa.h5\n",
      "  Visit 11690:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11690_inference_6d5bb4aa.h5\n",
      "  Visit 1248:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1248_inference_6d5bb4aa.h5\n",
      "  Visit 11724:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11724_inference_6d5bb4aa.h5\n",
      "\n",
      "DatasetLoader(40 visits, 1 paths)\n",
      "  Cutouts: 57905 across 40 visits\n",
      "  Features: 57905 across 40 visits\n",
      "Available visits: [322, 346, 358, 1178, 1184, 1204, 1206, 1214, 1220, 1242]...\n",
      "\n",
      "Checking for existing inference results...\n",
      "Syncing inference registry for /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm...\n",
      "Saved inference registry to /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm/inference/inference_registry.json\n",
      "Registry sync complete: added 0, removed 0 entries\n",
      "Available inference files in /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm:\n",
      "  Visit 1214:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1214_inference_6d5bb4aa.h5\n",
      "  Visit 29336:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_29336_inference_6d5bb4aa.h5\n",
      "  Visit 22662:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_22662_inference_6d5bb4aa.h5\n",
      "  Visit 358:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_358_inference_6d5bb4aa.h5\n",
      "  Visit 17904:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17904_inference_6d5bb4aa.h5\n",
      "  Visit 23718:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_23718_inference_6d5bb4aa.h5\n",
      "  Visit 19696:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_19696_inference_6d5bb4aa.h5\n",
      "  Visit 17948:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17948_inference_6d5bb4aa.h5\n",
      "  Visit 1178:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1178_inference_6d5bb4aa.h5\n",
      "  Visit 11694:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11694_inference_6d5bb4aa.h5\n",
      "  Visit 11740:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11740_inference_6d5bb4aa.h5\n",
      "  Visit 11696:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11696_inference_6d5bb4aa.h5\n",
      "  Visit 1204:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1204_inference_6d5bb4aa.h5\n",
      "  Visit 1220:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1220_inference_6d5bb4aa.h5\n",
      "  Visit 17926:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17926_inference_6d5bb4aa.h5\n",
      "  Visit 30490:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_30490_inference_6d5bb4aa.h5\n",
      "  Visit 17950:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17950_inference_6d5bb4aa.h5\n",
      "  Visit 19684:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_19684_inference_6d5bb4aa.h5\n",
      "  Visit 17900:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17900_inference_6d5bb4aa.h5\n",
      "  Visit 19680:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_19680_inference_6d5bb4aa.h5\n",
      "  Visit 23706:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_23706_inference_6d5bb4aa.h5\n",
      "  Visit 17906:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_17906_inference_6d5bb4aa.h5\n",
      "  Visit 23694:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_23694_inference_6d5bb4aa.h5\n",
      "  Visit 22632:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_22632_inference_6d5bb4aa.h5\n",
      "  Visit 30482:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_30482_inference_6d5bb4aa.h5\n",
      "  Visit 1206:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1206_inference_6d5bb4aa.h5\n",
      "  Visit 346:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_346_inference_6d5bb4aa.h5\n",
      "  Visit 11710:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11710_inference_6d5bb4aa.h5\n",
      "  Visit 11698:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11698_inference_6d5bb4aa.h5\n",
      "  Visit 23704:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_23704_inference_6d5bb4aa.h5\n",
      "  Visit 11738:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11738_inference_6d5bb4aa.h5\n",
      "  Visit 1184:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1184_inference_6d5bb4aa.h5\n",
      "  Visit 11704:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11704_inference_6d5bb4aa.h5\n",
      "  Visit 1242:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1242_inference_6d5bb4aa.h5\n",
      "  Visit 19694:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_19694_inference_6d5bb4aa.h5\n",
      "  Visit 322:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_322_inference_6d5bb4aa.h5\n",
      "  Visit 11690:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11690_inference_6d5bb4aa.h5\n",
      "  Visit 1248:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_1248_inference_6d5bb4aa.h5\n",
      "  Visit 11724:\n",
      "    Model hash: 6d5bb4aa\n",
      "      File: visit_11724_inference_6d5bb4aa.h5\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "dataset_loader = DatasetLoader(DATA_PATH)\n",
    "\n",
    "# Display dataset information\n",
    "print(f\"\\n{dataset_loader}\")\n",
    "print(f\"Available visits: {dataset_loader.visits[:10]}...\" if len(dataset_loader.visits) > 10 else f\"Available visits: {dataset_loader.visits}\")\n",
    "\n",
    "# Check for existing inference results\n",
    "if MODEL_HASH:\n",
    "    print(\"\\nChecking for existing inference results...\")\n",
    "    dataset_loader.sync_inference_registry()\n",
    "    dataset_loader.list_available_inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb83dfd",
   "metadata": {},
   "source": [
    "## 2. Generate or Load Inference Results\n",
    "\n",
    "We can either run new inference or load existing results. For demonstration, we'll show both approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61cf3598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing inference results by model hash...\n",
      "Loaded inference loader for visit 322, model 6d5bb4aa\n",
      "Loaded inference loader for visit 346, model 6d5bb4aa\n",
      "Loaded inference loader for visit 358, model 6d5bb4aa\n",
      "Loaded inference loader for visit 1178, model 6d5bb4aa\n",
      "Loaded inference loader for visit 1184, model 6d5bb4aa\n",
      "Loaded inference loader for visit 1204, model 6d5bb4aa\n",
      "Loaded inference loader for visit 1206, model 6d5bb4aa\n",
      "Loaded inference loader for visit 1214, model 6d5bb4aa\n",
      "Loaded inference loader for visit 1220, model 6d5bb4aa\n",
      "Loaded inference loader for visit 1242, model 6d5bb4aa\n",
      "Loaded inference loader for visit 1248, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11690, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11694, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11696, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11698, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11704, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11710, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11724, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11738, model 6d5bb4aa\n",
      "Loaded inference loader for visit 11740, model 6d5bb4aa\n",
      "Loaded inference loader for visit 17900, model 6d5bb4aa\n",
      "Loaded inference loader for visit 17904, model 6d5bb4aa\n",
      "Loaded inference loader for visit 17906, model 6d5bb4aa\n",
      "Loaded inference loader for visit 17926, model 6d5bb4aa\n",
      "Loaded inference loader for visit 17948, model 6d5bb4aa\n",
      "Loaded inference loader for visit 17950, model 6d5bb4aa\n",
      "Loaded inference loader for visit 19680, model 6d5bb4aa\n",
      "Loaded inference loader for visit 19684, model 6d5bb4aa\n",
      "Loaded inference loader for visit 19694, model 6d5bb4aa\n",
      "Loaded inference loader for visit 19696, model 6d5bb4aa\n",
      "Loaded inference loader for visit 22632, model 6d5bb4aa\n",
      "Loaded inference loader for visit 22662, model 6d5bb4aa\n",
      "Loaded inference loader for visit 23694, model 6d5bb4aa\n",
      "Loaded inference loader for visit 23704, model 6d5bb4aa\n",
      "Loaded inference loader for visit 23706, model 6d5bb4aa\n",
      "Loaded inference loader for visit 23718, model 6d5bb4aa\n",
      "Loaded inference loader for visit 29336, model 6d5bb4aa\n",
      "No inference results found in registry for visit 29350, model hash 6d5bb4aa\n",
      "Loaded inference loader for visit 30482, model 6d5bb4aa\n",
      "Loaded inference loader for visit 30490, model 6d5bb4aa\n",
      "Loaded inference results for 39 visits\n",
      "\n",
      "Successfully loaded inference results for 39 visits\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Check for existing inference results\n",
    "\"\"\"\n",
    "print(\"Checking for existing inference results...\")\n",
    "inference_results = dataset_loader.check_or_run_inference(WEIGHTS_PATH)\n",
    "\"\"\"  \n",
    "# Option 2: load from the HASH\n",
    "print(\"Loading existing inference results by model hash...\")\n",
    "inference_results = {}\n",
    "\n",
    "for visit in dataset_loader.visits:\n",
    "    inference_loader = dataset_loader.get_inference_loader(\n",
    "        visit=visit,\n",
    "        model_hash=MODEL_HASH\n",
    "    )\n",
    "    if inference_loader and inference_loader.has_inference_results():\n",
    "        inference_results[visit] = inference_loader\n",
    "        \n",
    "print(f\"Loaded inference results for {len(inference_results)} visits\")\n",
    "    \n",
    "\n",
    "\n",
    "# Verify we have results\n",
    "if not inference_results:\n",
    "    raise ValueError(\"No inference results available. Please run inference first.\")\n",
    "    \n",
    "print(f\"\\nSuccessfully loaded inference results for {len(inference_results)} visits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3e497a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating inference results...\n",
      "Total samples: 57,328\n",
      "Positive samples: 12,991.0 (22.7%)\n",
      "Predicted positive: 13,135.0 (22.9%)\n"
     ]
    }
   ],
   "source": [
    "# Aggregate results across all visits\n",
    "print(\"Aggregating inference results...\")\n",
    "\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_source_ids = []\n",
    "\n",
    "for visit, inference_loader in inference_results.items():\n",
    "    all_predictions.append(inference_loader.predictions)\n",
    "    all_labels.append(inference_loader.labels)\n",
    "    all_source_ids.append(inference_loader.ids)\n",
    "\n",
    "# Concatenate results\n",
    "predictions = np.concatenate(all_predictions)\n",
    "labels = np.concatenate(all_labels)\n",
    "source_ids = np.concatenate(all_source_ids)\n",
    "\n",
    "print(f\"Total samples: {len(predictions):,}\")\n",
    "print(f\"Positive samples: {np.sum(labels):,} ({np.mean(labels)*100:.1f}%)\")\n",
    "print(f\"Predicted positive: {np.sum(predictions):,} ({np.mean(predictions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70809066",
   "metadata": {},
   "source": [
    "## 3. Basic Metrics Evaluation\n",
    "\n",
    "Let's compute and display the standard classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76146264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing evaluation metrics...\n",
      "\n",
      "============================================================\n",
      "MODEL EVALUATION SUMMARY\n",
      "============================================================\n",
      "Accuracy...................... 0.9857\n",
      "Precision..................... 0.9632\n",
      "Recall........................ 0.9739\n",
      "F1 Score...................... 0.9685\n",
      "Specificity................... 0.9891\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create metrics object\n",
    "print(\"Computing evaluation metrics...\")\n",
    "metrics = EvaluationMetrics(predictions, labels)\n",
    "\n",
    "# Display summary\n",
    "summary = metrics.summary()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for metric_name, value in summary.items():\n",
    "    print(f\"{metric_name.replace('_', ' ').title():.<30} {value:.4f}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00d72c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Analysis:\n",
      "----------------------------------------\n",
      "True Positive................. 12,652\n",
      "True Negative................. 43,854\n",
      "False Positive................ 483\n",
      "False Negative................ 339\n",
      "True Positive Rate............ 0.9739\n",
      "True Negative Rate............ 0.9891\n",
      "Positive Predictive Value..... 0.9632\n",
      "Negative Predictive Value..... 0.9923\n",
      "False Positive Rate........... 0.0109\n",
      "False Negative Rate........... 0.0261\n",
      "Total Samples................. 57,328\n"
     ]
    }
   ],
   "source": [
    "# Detailed confusion matrix statistics\n",
    "print(\"\\nConfusion Matrix Analysis:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "cm_stats = metrics.get_confusion_matrix_stats()\n",
    "for key, value in cm_stats.items():\n",
    "    if isinstance(value, (int, np.integer)):\n",
    "        print(f\"{key.replace('_', ' ').title():.<30} {value:,}\")\n",
    "    else:\n",
    "        print(f\"{key.replace('_', ' ').title():.<30} {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c989e04f",
   "metadata": {},
   "source": [
    "## 4. Interactive Evaluation Dashboard\n",
    "\n",
    "Create an interactive Bokeh dashboard with all evaluation plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6af3e621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation dashboard...\n",
      "Dashboard saved to ../saved/test_eval/notebook/evaluation_dashboard.html\n",
      " Evaluation dashboard saved to: ../saved/test_eval/notebook/evaluation_dashboard.html\n",
      "Dashboard saved to ../saved/test_eval/notebook/evaluation_dashboard.html\n",
      " Evaluation dashboard saved to: ../saved/test_eval/notebook/evaluation_dashboard.html\n"
     ]
    }
   ],
   "source": [
    "# Create evaluation dashboard\n",
    "print(\"Creating evaluation dashboard...\")\n",
    "\n",
    "model_name = Path(WEIGHTS_PATH).name if WEIGHTS_PATH else f\"Model_{MODEL_HASH}\"\n",
    "dashboard_path = output_dir / \"evaluation_dashboard.html\"\n",
    "\n",
    "evaluation_dashboard = create_evaluation_dashboard(\n",
    "    metrics,\n",
    "    output_path=dashboard_path,\n",
    "    title=f\"Model Evaluation - {model_name}\"\n",
    ")\n",
    "\n",
    "print(f\" Evaluation dashboard saved to: {dashboard_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336c66f",
   "metadata": {},
   "source": [
    "## 5. Interpretability Analysis with UMAP\n",
    "\n",
    "Now let's perform UMAP-based interpretability analysis to understand what the model has learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b126d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for interpretability analysis\n",
    "INTERPRETABILITY_CONFIG = {\n",
    "    'max_samples': 1000,  # Limit samples for visualization performance\n",
    "    'layer_name': 'fc1',  # Which layer to extract features from\n",
    "    'umap': {\n",
    "        'n_neighbors': 15,\n",
    "        'min_dist': 0.1,\n",
    "        'n_components': 2,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    'clustering': {\n",
    "        'n_components_range': [5, 15]\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87078236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating evaluation dataset for interpretability...\n",
      "Using visits: [322, 346, 358]\n",
      "Building inference dataset index across visits...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created inference dataset with 1805 samples across 3 visits\n",
      "Created lazy dataset with 1805 samples\n",
      "Created evaluation dataset with 1805 samples\n"
     ]
    }
   ],
   "source": [
    "# Create dataset for interpretability analysis\n",
    "print(\"Creating evaluation dataset for interpretability...\")\n",
    "\n",
    "# Select subset of visits for performance (optional)\n",
    "selected_visits = dataset_loader.visits[:3]  # Use first 3 visits for demo\n",
    "print(f\"Using visits: {selected_visits}\")\n",
    "\n",
    "eval_dataset = PytorchDataset.create_inference_dataset(\n",
    "    dataset_loader, \n",
    "    visits=selected_visits\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "print(f\"Created evaluation dataset with {len(eval_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "002d1547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing UMAP interpreter...\n",
      "TensorBoard logging to: runs/gpu_training_845962\n",
      "Run 'tensorboard --logdir=runs' to view logs\n",
      "Extracting features from layer: fc1\n",
      "Extracting features from layer: fc1\n",
      "Processing batch 1/29\n",
      "Processing batch 11/29\n",
      "Processing batch 11/29\n",
      "Processing batch 21/29\n",
      "Extracted features shape: (1805, 128)\n",
      "Extracted features shape: (1805, 128)\n",
      "Processing batch 21/29\n",
      "Extracted features shape: (1805, 128)\n",
      "Extracted features shape: (1805, 128)\n"
     ]
    }
   ],
   "source": [
    "# Initialize UMAP interpreter\n",
    "if not WEIGHTS_PATH:\n",
    "    print(\"Warning: UMAP interpretability requires WEIGHTS_PATH, skipping...\")\n",
    "else:\n",
    "    print(\"Initializing UMAP interpreter...\")\n",
    "    interpreter = UMAPInterpreter(WEIGHTS_PATH)\n",
    "    \n",
    "    # Extract features from specified layer\n",
    "    print(f\"Extracting features from layer: {INTERPRETABILITY_CONFIG['layer_name']}\")\n",
    "    features = interpreter.extract_features(\n",
    "        eval_dataloader, \n",
    "        layer_name=INTERPRETABILITY_CONFIG['layer_name']\n",
    "    )\n",
    "    \n",
    "    print(f\"Extracted features shape: {features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "833af89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting UMAP embedding...\n",
      "UMAP embedding shape: (1805, 2)\n",
      "  X range: [-4.78, 10.66]\n",
      "  Y range: [-1.57, 11.39]\n",
      "UMAP embedding shape: (1805, 2)\n",
      "  X range: [-4.78, 10.66]\n",
      "  Y range: [-1.57, 11.39]\n"
     ]
    }
   ],
   "source": [
    "# Fit UMAP embedding\n",
    "if WEIGHTS_PATH:\n",
    "    print(\"Fitting UMAP embedding...\")\n",
    "    umap_embedding = interpreter.fit_umap(**INTERPRETABILITY_CONFIG['umap'])\n",
    "    \n",
    "    print(f\"UMAP embedding shape: {umap_embedding.shape}\")\n",
    "    print(f\"  X range: [{umap_embedding[:, 0].min():.2f}, {umap_embedding[:, 0].max():.2f}]\")\n",
    "    print(f\"  Y range: [{umap_embedding[:, 1].min():.2f}, {umap_embedding[:, 1].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66b10104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating interpretability dataframe...\n",
      "Creating embeddable images for hover tooltips...\n",
      "Processed 640 images...\n",
      "Processed 640 images...\n",
      "Processed 1280 images...\n",
      "Processed 1280 images...\n",
      "Created 1805 embeddable images\n",
      "Performing clustering analysis...\n",
      "Created 1805 embeddable images\n",
      "Performing clustering analysis...\n",
      "✓ Created interpretability dataframe with 1805 samples\n",
      "  Columns: ['umap_x', 'umap_y', 'prediction', 'true_label', 'correct', 'class_type', 'image', 'cluster']\n",
      "  Clusters found: ['0', '1', '2', '3', '4', '5', '6']\n",
      "✓ Created interpretability dataframe with 1805 samples\n",
      "  Columns: ['umap_x', 'umap_y', 'prediction', 'true_label', 'correct', 'class_type', 'image', 'cluster']\n",
      "  Clusters found: ['0', '1', '2', '3', '4', '5', '6']\n"
     ]
    }
   ],
   "source": [
    "# Create interpretability dataframe\n",
    "if WEIGHTS_PATH:\n",
    "    print(\"Creating interpretability dataframe...\")\n",
    "    \n",
    "    # Get predictions for the evaluation dataset\n",
    "    eval_predictions = predictions[:len(eval_dataset)]\n",
    "    eval_labels = labels[:len(eval_dataset)]\n",
    "    \n",
    "    # Optional: Add additional features (e.g., SNR if available)\n",
    "    additional_features = {}\n",
    "    # Example: additional_features['SNR'] = your_snr_values\n",
    "    \n",
    "    # Create dataframe with UMAP coordinates and images\n",
    "    interp_df = interpreter.create_interpretability_dataframe(\n",
    "        eval_predictions,\n",
    "        eval_labels,\n",
    "        eval_dataloader,\n",
    "        additional_features=additional_features\n",
    "    )\n",
    "    \n",
    "    # Add clustering\n",
    "    print(\"Performing clustering analysis...\")\n",
    "    interp_df = interpreter.add_clustering_to_dataframe(\n",
    "        interp_df, \n",
    "        tuple(INTERPRETABILITY_CONFIG['clustering']['n_components_range'])\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Created interpretability dataframe with {len(interp_df)} samples\")\n",
    "    print(f\"  Columns: {list(interp_df.columns)}\")\n",
    "    print(f\"  Clusters found: {sorted(interp_df['cluster'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5907f3b",
   "metadata": {},
   "source": [
    "## 6. Interactive Interpretability Dashboard\n",
    "\n",
    "Create an interactive dashboard for exploring the UMAP visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab44efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating interpretability dashboard...\n",
      "Extracting features...\n",
      "Extracting features from layer: fc1\n",
      "Processing batch 1/29\n",
      "Processing batch 11/29\n",
      "Processing batch 21/29\n",
      "Extracted features shape: (1805, 128)\n",
      "Fitting UMAP...\n",
      "Extracted features shape: (1805, 128)\n",
      "Fitting UMAP...\n",
      "Creating visualization dataframe (max 1000 samples)...\n",
      "Creating embeddable images for hover tooltips...\n",
      "Creating visualization dataframe (max 1000 samples)...\n",
      "Creating embeddable images for hover tooltips...\n",
      "Processed 640 images...\n",
      "Processed 1280 images...\n",
      "Processed 640 images...\n",
      "Processed 1280 images...\n",
      "Created 1805 embeddable images\n",
      "Performing clustering...\n",
      "Created 1805 embeddable images\n",
      "Performing clustering...\n",
      "Created visualization dataframe with 1805 samples using fc1 features\n",
      "Interpretability dashboard saved to ../saved/test_eval/notebook/interpretability_dashboard.html\n",
      "Interpretability dashboard saved to: ../saved/test_eval/notebook/interpretability_dashboard.html\n",
      "Created visualization dataframe with 1805 samples using fc1 features\n",
      "Interpretability dashboard saved to ../saved/test_eval/notebook/interpretability_dashboard.html\n",
      "Interpretability dashboard saved to: ../saved/test_eval/notebook/interpretability_dashboard.html\n"
     ]
    }
   ],
   "source": [
    "# Create interpretability dashboard\n",
    "if WEIGHTS_PATH:\n",
    "    print(\"Creating interpretability dashboard...\")\n",
    "    \n",
    "    interp_dashboard_path = output_dir / \"interpretability_dashboard.html\"\n",
    "    \n",
    "    interp_dashboard = create_interpretability_dashboard(\n",
    "        interpreter,\n",
    "        eval_dataloader,\n",
    "        eval_predictions,\n",
    "        eval_labels,\n",
    "        output_path=interp_dashboard_path,\n",
    "        additional_features=additional_features,\n",
    "        config={'interpretability': INTERPRETABILITY_CONFIG}\n",
    "    )\n",
    "    \n",
    "    print(f\"Interpretability dashboard saved to: {interp_dashboard_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fb85c",
   "metadata": {},
   "source": [
    "## 8. Save Analysis Results\n",
    "\n",
    "Save all results for future reference and sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d08eea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Analysis results saved to: ../saved/test_eval/notebook/evaluation_summary.yaml\n",
      "✓ Interpretability data saved to: ../saved/test_eval/notebook/interpretability_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Save analysis results\n",
    "results_summary = {\n",
    "    'model_info': {\n",
    "        'weights_path': str(WEIGHTS_PATH) if WEIGHTS_PATH else None,\n",
    "        'model_hash': MODEL_HASH,\n",
    "        'data_path': str(DATA_PATH),\n",
    "        'visits_evaluated': list(inference_results.keys()),\n",
    "        'total_samples': int(len(predictions))\n",
    "    },\n",
    "    'metrics': {k: float(v) for k, v in summary.items()},\n",
    "    'confusion_matrix_stats': {k: int(v) if isinstance(v, (int, np.integer)) else float(v) \n",
    "                              for k, v in cm_stats.items()},\n",
    "}\n",
    "\n",
    "if WEIGHTS_PATH:\n",
    "    results_summary['interpretability'] = {\n",
    "        'config': INTERPRETABILITY_CONFIG,\n",
    "        'umap_embedding_shape': list(umap_embedding.shape),\n",
    "        'n_clusters': int(n_clusters),\n",
    "        'cluster_performance': perf_df.to_dict('records') if 'perf_df' in locals() else None\n",
    "    }\n",
    "\n",
    "# Save to YAML file\n",
    "results_file = output_dir / \"evaluation_summary.yaml\"\n",
    "with open(results_file, 'w') as f:\n",
    "    yaml.dump(results_summary, f, default_flow_style=False)\n",
    "\n",
    "print(f\"Analysis results saved to: {results_file}\")\n",
    "\n",
    "# Save interpretability dataframe\n",
    "if WEIGHTS_PATH:\n",
    "    interp_csv = output_dir / \"interpretability_data.csv\"\n",
    "    interp_df.drop(columns=['image']).to_csv(interp_csv, index=False)  # Drop image column for CSV\n",
    "    print(f\"Interpretability data saved to: {interp_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ML",
   "language": "python",
   "name": "env_ML"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
