{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b928a094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 18:51:35.636752: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-29 18:51:35.654619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753807895.676344 3968993 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753807895.682654 3968993 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753807895.698980 3968993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753807895.698998 3968993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753807895.698999 3968993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753807895.699001 3968993 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-29 18:51:35.704583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from ML4transients.training import PytorchDataset, CustomCNN, get_trainer, get_loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5107059f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building sample index...\n",
      "Creating splits from 57905 samples...\n",
      "Loading 40533 cutouts...\n",
      "Loading 5791 cutouts...\n",
      "Loading 11581 cutouts...\n"
     ]
    }
   ],
   "source": [
    "datasets = PytorchDataset.create_splits('/sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc188cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets['train'] \n",
    "test_dataset = datasets['test'] \n",
    "val_dataset = datasets['val'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b440b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "config = {\n",
    "    \"epochs\": 2,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 128,\n",
    "    \"num_iter_per_epoch\": 400,\n",
    "    \"epoch_decay_start\": 80,\n",
    "    \"num_workers\": 0,\n",
    "    \"output_dir\":\"../saved/training_test\",\n",
    "    \"model_params\": {\n",
    "        \"input_shape\": [30, 30, 1],\n",
    "        \"num_classes\": 2,\n",
    "        \"filters_1\": 32,\n",
    "        \"filters_2\": 64,\n",
    "        \"dropout_1\": 0.25,\n",
    "        \"dropout_2\": 0.25,\n",
    "        \"dropout_3\": 0.5,\n",
    "        \"units\": 128\n",
    "    }\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cedf3419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logging to: runs/experiment\n",
      "Run 'tensorboard --logdir=runs' to view logs\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config['batch_size'],  # 128 from your config\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers']  # 4 from your config\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=config['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config['batch_size'], \n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers']\n",
    ")\n",
    "trainer = get_trainer(\"standard\", config)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea88238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train_one_epoch(1, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc46d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_acc = trainer.fit(train_loader, test_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce26751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logging to: runs/experiment\n",
      "Run 'tensorboard --logdir=runs' to view logs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "trainer = get_trainer(\"standard\", config)\n",
    "trainer.model.load_state_dict(torch.load('/sps/lsst/groups/transients/HSC/fouchez/raphael/training/simple_run/model_best.pth', map_location=torch.device('cpu')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b304f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "inference_loader = DataLoader(\n",
    "    val_dataset,  # Replace with your dataset\n",
    "    batch_size=128,  # Batch size of 1 for inference\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1055303a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML4transients.evaluation import infer \n",
    "result = infer(inference_loader, trainer= trainer, return_preds=True, compute_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed8205dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9528578829217752\n",
      "0.7475392850975652\n",
      "0.025902262130892764\n",
      "0.021239854947332066\n",
      "0.20531859782420997\n"
     ]
    }
   ],
   "source": [
    "print(result[\"accuracy\"])\n",
    "print(result[\"confusion_matrix\"][0][0])\n",
    "print(result[\"confusion_matrix\"][0][1])\n",
    "print(result[\"confusion_matrix\"][1][0])\n",
    "print(result[\"confusion_matrix\"][1][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ML",
   "language": "python",
   "name": "env_ML"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
