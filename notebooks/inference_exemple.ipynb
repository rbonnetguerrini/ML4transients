{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9887d153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No inference results found for model: /sps/lsst/groups/transients/HSC/fouchez/raphael/training/simple_run\n",
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 11:03:49.790727: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753952629.812992  663366 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753952629.819726  663366 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753952629.837181  663366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753952629.837198  663366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753952629.837201  663366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753952629.837203  663366 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-31 11:03:49.842902: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building inference dataset index...\n",
      "Created inference dataset with 57905 samples\n",
      "Loading 57905 cutouts for inference...\n",
      "TensorBoard logging to: runs/gpu_training_599259\n",
      "Run 'tensorboard --logdir=runs' to view logs\n",
      "Processing batch 0/1810\n",
      "Processing batch 10/1810\n",
      "Processing batch 20/1810\n",
      "Processing batch 30/1810\n",
      "Processing batch 40/1810\n",
      "Processing batch 50/1810\n",
      "Processing batch 60/1810\n",
      "Processing batch 70/1810\n",
      "Processing batch 80/1810\n",
      "Processing batch 90/1810\n",
      "Processing batch 100/1810\n",
      "Processing batch 110/1810\n",
      "Processing batch 120/1810\n",
      "Processing batch 130/1810\n",
      "Processing batch 140/1810\n",
      "Processing batch 150/1810\n",
      "Processing batch 160/1810\n",
      "Processing batch 170/1810\n",
      "Processing batch 180/1810\n",
      "Processing batch 190/1810\n",
      "Processing batch 200/1810\n",
      "Processing batch 210/1810\n",
      "Processing batch 220/1810\n",
      "Processing batch 230/1810\n",
      "Processing batch 240/1810\n",
      "Processing batch 250/1810\n",
      "Processing batch 260/1810\n",
      "Processing batch 270/1810\n",
      "Processing batch 280/1810\n",
      "Processing batch 290/1810\n",
      "Processing batch 300/1810\n",
      "Processing batch 310/1810\n",
      "Processing batch 320/1810\n",
      "Processing batch 330/1810\n",
      "Processing batch 340/1810\n",
      "Processing batch 350/1810\n",
      "Processing batch 360/1810\n",
      "Processing batch 370/1810\n",
      "Processing batch 380/1810\n",
      "Processing batch 390/1810\n",
      "Processing batch 400/1810\n",
      "Processing batch 410/1810\n",
      "Processing batch 420/1810\n",
      "Processing batch 430/1810\n",
      "Processing batch 440/1810\n",
      "Processing batch 450/1810\n",
      "Processing batch 460/1810\n",
      "Processing batch 470/1810\n",
      "Processing batch 480/1810\n",
      "Processing batch 490/1810\n",
      "Processing batch 500/1810\n",
      "Processing batch 510/1810\n",
      "Processing batch 520/1810\n",
      "Processing batch 530/1810\n",
      "Processing batch 540/1810\n",
      "Processing batch 550/1810\n",
      "Processing batch 560/1810\n",
      "Processing batch 570/1810\n",
      "Processing batch 580/1810\n",
      "Processing batch 590/1810\n",
      "Processing batch 600/1810\n",
      "Processing batch 610/1810\n",
      "Processing batch 620/1810\n",
      "Processing batch 630/1810\n",
      "Processing batch 640/1810\n",
      "Processing batch 650/1810\n",
      "Processing batch 660/1810\n",
      "Processing batch 670/1810\n",
      "Processing batch 680/1810\n",
      "Processing batch 690/1810\n",
      "Processing batch 700/1810\n",
      "Processing batch 710/1810\n",
      "Processing batch 720/1810\n",
      "Processing batch 730/1810\n",
      "Processing batch 740/1810\n",
      "Processing batch 750/1810\n",
      "Processing batch 760/1810\n",
      "Processing batch 770/1810\n",
      "Processing batch 780/1810\n",
      "Processing batch 790/1810\n",
      "Processing batch 800/1810\n",
      "Processing batch 810/1810\n",
      "Processing batch 820/1810\n",
      "Processing batch 830/1810\n",
      "Processing batch 840/1810\n",
      "Processing batch 850/1810\n",
      "Processing batch 860/1810\n",
      "Processing batch 870/1810\n",
      "Processing batch 880/1810\n",
      "Processing batch 890/1810\n",
      "Processing batch 900/1810\n",
      "Processing batch 910/1810\n",
      "Processing batch 920/1810\n",
      "Processing batch 930/1810\n",
      "Processing batch 940/1810\n",
      "Processing batch 950/1810\n",
      "Processing batch 960/1810\n",
      "Processing batch 970/1810\n",
      "Processing batch 980/1810\n",
      "Processing batch 990/1810\n",
      "Processing batch 1000/1810\n",
      "Processing batch 1010/1810\n",
      "Processing batch 1020/1810\n",
      "Processing batch 1030/1810\n",
      "Processing batch 1040/1810\n",
      "Processing batch 1050/1810\n",
      "Processing batch 1060/1810\n",
      "Processing batch 1070/1810\n",
      "Processing batch 1080/1810\n",
      "Processing batch 1090/1810\n",
      "Processing batch 1100/1810\n",
      "Processing batch 1110/1810\n",
      "Processing batch 1120/1810\n",
      "Processing batch 1130/1810\n",
      "Processing batch 1140/1810\n",
      "Processing batch 1150/1810\n",
      "Processing batch 1160/1810\n",
      "Processing batch 1170/1810\n",
      "Processing batch 1180/1810\n",
      "Processing batch 1190/1810\n",
      "Processing batch 1200/1810\n",
      "Processing batch 1210/1810\n",
      "Processing batch 1220/1810\n",
      "Processing batch 1230/1810\n",
      "Processing batch 1240/1810\n",
      "Processing batch 1250/1810\n",
      "Processing batch 1260/1810\n",
      "Processing batch 1270/1810\n",
      "Processing batch 1280/1810\n",
      "Processing batch 1290/1810\n",
      "Processing batch 1300/1810\n",
      "Processing batch 1310/1810\n",
      "Processing batch 1320/1810\n",
      "Processing batch 1330/1810\n",
      "Processing batch 1340/1810\n",
      "Processing batch 1350/1810\n",
      "Processing batch 1360/1810\n",
      "Processing batch 1370/1810\n",
      "Processing batch 1380/1810\n",
      "Processing batch 1390/1810\n",
      "Processing batch 1400/1810\n",
      "Processing batch 1410/1810\n",
      "Processing batch 1420/1810\n",
      "Processing batch 1430/1810\n",
      "Processing batch 1440/1810\n",
      "Processing batch 1450/1810\n",
      "Processing batch 1460/1810\n",
      "Processing batch 1470/1810\n",
      "Processing batch 1480/1810\n",
      "Processing batch 1490/1810\n",
      "Processing batch 1500/1810\n",
      "Processing batch 1510/1810\n",
      "Processing batch 1520/1810\n",
      "Processing batch 1530/1810\n",
      "Processing batch 1540/1810\n",
      "Processing batch 1550/1810\n",
      "Processing batch 1560/1810\n",
      "Processing batch 1570/1810\n",
      "Processing batch 1580/1810\n",
      "Processing batch 1590/1810\n",
      "Processing batch 1600/1810\n",
      "Processing batch 1610/1810\n",
      "Processing batch 1620/1810\n",
      "Processing batch 1630/1810\n",
      "Processing batch 1640/1810\n",
      "Processing batch 1650/1810\n",
      "Processing batch 1660/1810\n",
      "Processing batch 1670/1810\n",
      "Processing batch 1680/1810\n",
      "Processing batch 1690/1810\n",
      "Processing batch 1700/1810\n",
      "Processing batch 1710/1810\n",
      "Processing batch 1720/1810\n",
      "Processing batch 1730/1810\n",
      "Processing batch 1740/1810\n",
      "Processing batch 1750/1810\n",
      "Processing batch 1760/1810\n",
      "Processing batch 1770/1810\n",
      "Processing batch 1780/1810\n",
      "Processing batch 1790/1810\n",
      "Processing batch 1800/1810\n",
      "Inference results saved to /sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm/inference/inference_results_6d5bb4aa.h5\n"
     ]
    }
   ],
   "source": [
    "from ML4transients.data_access import DatasetLoader\n",
    "\n",
    "# Load your dataset\n",
    "loader = DatasetLoader('/sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm')\n",
    "\n",
    "# Check for existing inference or run new inference\n",
    "weights_path = '/sps/lsst/groups/transients/HSC/fouchez/raphael/training/simple_run'\n",
    "inference_loader = loader.check_or_run_inference(weights_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dad2b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9855970986961402\n",
      "Predictions shape: (57905,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'some_dia_source_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minference_loader\u001b[38;5;241m.\u001b[39mpredictions\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Get specific result\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m inference_loader\u001b[38;5;241m.\u001b[39mget_results_by_id(\u001b[43msome_dia_source_id\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, True label: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'some_dia_source_id' is not defined"
     ]
    }
   ],
   "source": [
    "if inference_loader:\n",
    "    # Access results quickly\n",
    "    print(f\"Accuracy: {inference_loader.metrics['accuracy']}\")\n",
    "    print(f\"Predictions shape: {inference_loader.predictions.shape}\")\n",
    "    \n",
    "    # Get specific result\n",
    "    result = inference_loader.get_results_by_id(some_dia_source_id)\n",
    "    if result:\n",
    "        print(f\"Prediction: {result['prediction']}, True label: {result['label']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ML",
   "language": "python",
   "name": "env_ML"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
