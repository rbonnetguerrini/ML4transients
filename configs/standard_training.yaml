# Standard training configuration with optimized hyperparameters from bayes
data:
  path: "/sps/lsst/groups/transients/HSC/fouchez/raphael/data/rc2_norm"
  visits: null  # Use all visits, or specify list 
  test_size: 0.2
  val_size: 0.1

training:
  trainer_type: "standard"
  epochs: 1500
  learning_rate: 0.001
  batch_size: 256  # Optimized from Bayesian search
  num_iter_per_epoch: 400
  epoch_decay_start: 80
  num_workers: 4 
  output_dir: "/sps/lsst/groups/transients/HSC/fouchez/raphael/training/optimized_run"

  # TensorBoard configuration
  use_tensorboard: true
  tensorboard_log_dir: "runs"
  experiment_name: "optimized_standard"
  log_interval: 100
  
  early_stopping:
    enabled: true
    monitor: "loss"       
    mode: "min"            
    patience_lr_changes: 5  # Stop after 5 LR changes without improvement
    min_delta: 0.0
    
  bayes_search:
    enabled: false
    
  model_params:
    input_shape: [30, 30, 1]
    num_classes: 2
    num_conv_blocks: 4                    # Optimized: 4 conv blocks
    filters_1: 16                         # Optimized
    filters_2: 64                         # Optimized  
    filters_3: 256                        # Optimized
    filters_4: 384                        # Optimized (close to 384)
    dropout_1: 0.41                       # Optimized: 0.4113467995641051
    dropout_2: 0.32                       # Optimized: 0.31532548735236227
    dropout_3: 0.49                       # Optimized: 0.4884026164429377
    units: 64                             # Optimized

random_state: 42
